{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# you.com <> dspy: ChatVC\n",
    "\n",
    "A chatbot that I could ask questions about early-stage investing and any relevants news to potential investment opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install dspy==0.1.5\n",
    "! pip install dotenv==0.0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assumes a .env file exists with api keys YDC_API_KEY and OPENAI_API_KEY\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Language Model (lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-4o')\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature\n",
    "\n",
    "Every call to the LM in a DSPy program needs to have a `Signature`.\n",
    "\n",
    "A signature consists of three simple elements:\n",
    "\n",
    "A minimal description of the sub-task the LM is supposed to solve.\n",
    "A description of one or more input fields (e.g., input question) that we will give to the LM.\n",
    "A description of one or more output fields (e.g., the question's answer) that we will expect from the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with wise suggestions\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 40-50 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If you are advising a founder on how they should choose an invester in their company, what qualities should they look for?\n",
      "Predicted Answer: Question: If you are advising a founder on how they should choose an investor in their company, what qualities should they look for?\n",
      "Answer: Look for investors who align with your vision, bring industry expertise, and offer valuable networks. Ensure they have a track record of supporting startups and can provide strategic guidance. Compatibility in values and communication style is also crucial for a successful partnership.\n"
     ]
    }
   ],
   "source": [
    "question = \"If you are advising a founder on how they should choose an invester in their company, what qualities should they look for?\"\n",
    "\n",
    "# Define the predictor.\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Call the predictor on a particular input.\n",
    "pred = generate_answer(question=question)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Retriever Model (rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO has this been merged?\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from typing import Any, Literal, Optional, Union\n",
    "\n",
    "import requests\n",
    "\n",
    "import dspy\n",
    "from dsp.utils import dotdict\n",
    "\n",
    "\n",
    "class YouRM(dspy.Retrieve):\n",
    "    \"\"\"Retriever for You.com's Search and News API.\n",
    "\n",
    "    [API reference](https://documentation.you.com/api-reference/)\n",
    "\n",
    "    Args:\n",
    "        ydc_api_key: you.com API key, if `YDC_API_KEY` is not set in the environment\n",
    "        k: If ``endpoint=\"search\"``, the max snippets to return per search hit.\n",
    "           If ``endpoint=\"news\"``, the max articles to return.\n",
    "        endpoint: you.com endpoints\n",
    "        num_web_results: The max number of web results to return, must be under 20\n",
    "        safesearch: Safesearch settings, one of \"off\", \"moderate\", \"strict\", defaults to moderate\n",
    "        country: Country code, ex: 'US' for United States, see API reference for more info\n",
    "        search_lang: (News API) Language codes, ex: 'en' for English, see API reference for more info\n",
    "        ui_lang: (News API) User interface language for the response, ex: 'en' for English.\n",
    "                            See API reference for more info\n",
    "        spellcheck: (News API) Whether to spell check query or not, defaults to True\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ydc_api_key: Optional[str] = None,\n",
    "        k: int = 3,\n",
    "        endpoint: Literal[\"search\", \"news\"] = \"search\",\n",
    "        num_web_results: Optional[int] = None,\n",
    "        safesearch: Optional[Literal[\"off\", \"moderate\", \"strict\"]] = None,\n",
    "        country: Optional[str] = None,\n",
    "        search_lang: Optional[str] = None,\n",
    "        ui_lang: Optional[str] = None,\n",
    "        spellcheck: Optional[bool] = None,\n",
    "    ):\n",
    "        super().__init__(k=k)\n",
    "\n",
    "        # Data validation\n",
    "        if not ydc_api_key and not os.environ.get(\"YDC_API_KEY\"):\n",
    "            raise RuntimeError('You must supply `ydc_api_key` or set environment variable \"YDC_API_KEY\"')\n",
    "\n",
    "        if endpoint not in (\"search\", \"news\"):\n",
    "            raise ValueError('`endpoint` must be either \"search\" or \"news\"')\n",
    "\n",
    "        # Raise warning if News API-specific fields are set but endpoint is not \"news\"\n",
    "        if endpoint != \"news\":\n",
    "            news_api_fields = (search_lang, ui_lang, spellcheck)\n",
    "            for field in news_api_fields:\n",
    "                if field:\n",
    "                    warnings.warn(\n",
    "                        (\n",
    "                            f\"News API-specific field '{field}' is set but `{endpoint=}`. \"\n",
    "                            \"This will have no effect.\"\n",
    "                        ),\n",
    "                        UserWarning,\n",
    "                    )\n",
    "\n",
    "        self.ydc_api_key = ydc_api_key or os.environ.get(\"YDC_API_KEY\")\n",
    "        self.endpoint = endpoint\n",
    "        self.num_web_results = num_web_results\n",
    "        self.safesearch = safesearch\n",
    "        self.country = country\n",
    "        self.search_lang = search_lang\n",
    "        self.ui_lang = ui_lang\n",
    "        self.spellcheck = spellcheck\n",
    "\n",
    "    def _generate_params(self, query: str) -> dict[str, Any]:\n",
    "        params = {\"safesearch\": self.safesearch, \"country\": self.country}\n",
    "\n",
    "        if self.endpoint == \"search\":\n",
    "            params.update(\n",
    "                query=query,\n",
    "                num_web_results=self.num_web_results,\n",
    "            )\n",
    "        elif self.endpoint == \"news\":\n",
    "            params.update(\n",
    "                q=query,\n",
    "                count=self.num_web_results,\n",
    "                search_lang=self.search_lang,\n",
    "                ui_lang=self.ui_lang,\n",
    "                spellcheck=self.spellcheck,\n",
    "            )\n",
    "\n",
    "        # Remove `None` values\n",
    "        params = {k: v for k, v in params.items() if v is not None}\n",
    "        return params\n",
    "\n",
    "    def forward(self, query_or_queries: Union[str, list[str]], k: Optional[int] = None) -> dspy.Prediction:\n",
    "        k = k if k is not None else self.k\n",
    "\n",
    "        queries = [query_or_queries] if isinstance(query_or_queries, str) else query_or_queries\n",
    "        docs: list[str]\n",
    "        for query in queries:\n",
    "            headers = {\"X-API-Key\": self.ydc_api_key}\n",
    "            params = self._generate_params(query)\n",
    "            response = requests.get(\n",
    "                f\"https://api.ydc-index.io/{self.endpoint}\",\n",
    "                params=params,\n",
    "                headers=headers,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            results = response.json()\n",
    "\n",
    "            if self.endpoint == \"search\":\n",
    "                docs = [snippet for hits in results[\"hits\"][:k] for snippet in hits[\"snippets\"]]\n",
    "            elif self.endpoint == \"news\":\n",
    "                docs = [article[\"description\"] for article in results[\"news\"][\"results\"][:k]]\n",
    "        return [dotdict({\"long_text\": document}) for document in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'long_text': \"It's not quite summer yet, though it might as well be ...\"},\n",
       " {'long_text': 'PRINCETON, NJ - The Princeton wrestling team announced Thursday that the program will be welcoming seven incoming freshman as a part of the Class of 2028.'},\n",
       " {'long_text': 'The new true crime series — from the creators of the award-winning podcast \"Father Wants Us Dead\" — investigates the 1989 cold-case killing of a Princeton grande dame.'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dspy.retrieve.you_rm import YouRM\n",
    "\n",
    "news_rm = YouRM(endpoint=\"news\")\n",
    "res = news_rm(\"Princeton\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve\n",
    "\n",
    "A module `dspy.Retrieve(k)` will search for the top-k passages that match a given query. \n",
    " \n",
    "By default, this will use the retriever we configure in `dspy.settings.configure()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=turbo, rm=news_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 passages for question: What is latest news about Princeton University? \n",
      " ------------------------------ \n",
      "\n",
      "1] Reunions events begin Thursday, May 23, and run through Sunday, May 26. \n",
      "\n",
      "2] More than a dozen students at Princeton University said they were ending their hunger strike amid continued anti-Israel demonstrations at the university. \n",
      "\n",
      "3] Over a dozen students at Princeton University have been on hunger strike for the past week as part of a Gaza solidarity encampment on campus protesting Israel’s war on Gaza and calling on the university to disclose and divest from companies with ties to Israel, among other demands. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What is latest news about Princeton University?\"\n",
    "\n",
    "retrieve = dspy.Retrieve(k=3)\n",
    "topK_passages = retrieve(question).passages\n",
    "\n",
    "print(f\"Top {retrieve.k} passages for question: {question} \\n\", '-' * 30, '\\n')\n",
    "\n",
    "for idx, passage in enumerate(topK_passages):\n",
    "    print(f'{idx+1}]', passage, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: RAG\n",
    "\n",
    "Given a question, we'll search for the latest news through you.com nws API and then feed them as context for answer generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature\n",
    "\n",
    "Let's start by defining this signature: `context, question --> answer.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with the news in the context\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant news\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"highlights key points in context - often between 50-100 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module\n",
    "\n",
    "* The `__init__` method will simply declare the sub-modules it needs: `dspy.Retrieve` and `dspy.ChainOfThought`. The latter is defined to implement our GenerateAnswer signature.\n",
    "* The `forward` method will describe the control flow of answering the question using the modules we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Princeton\n",
      "Predicted Answer: The Princeton wrestling team announced that they will be welcoming seven incoming freshmen as part of the Class of 2028. Additionally, a new true crime series investigates the 1989 cold-case killing of a Princeton grande dame.\n"
     ]
    }
   ],
   "source": [
    "my_question = \"Princeton\"\n",
    "\n",
    "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "uncompiled_rag = RAG()  # uncompiled (i.e., zero-shot) program\n",
    "pred = uncompiled_rag(my_question)\n",
    "\n",
    "# Print the contexts and the answer.\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "# print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspect the chain of thought for the LM - to iterate and modify signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with the news in the context\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant news\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: often between 50-100 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «It's not quite summer yet, though it might as well be ...»\n",
      "[2] «PRINCETON, NJ - The Princeton wrestling team announced Thursday that the program will be welcoming seven incoming freshman as a part of the Class of 2028.»\n",
      "[3] «The new true crime series — from the creators of the award-winning podcast \"Father Wants Us Dead\" — investigates the 1989 cold-case killing of a Princeton grande dame.»\n",
      "\n",
      "Question: Princeton\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m Context:\n",
      "[1] «It's not quite summer yet, though it might as well be ...»\n",
      "[2] «PRINCETON, NJ - The Princeton wrestling team announced Thursday that the program will be welcoming seven incoming freshman as a part of the Class of 2028.»\n",
      "[3] «The new true crime series — from the creators of the award-winning podcast \"Father Wants Us Dead\" — investigates the 1989 cold-case killing of a Princeton grande dame.»\n",
      "\n",
      "Question: What recent announcement did the Princeton wrestling team make?\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the answer. We need to identify any specific announcements related to the Princeton wrestling team mentioned in the context.\n",
      "\n",
      "Answer: The Princeton wrestling team announced that\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with the news in the context\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant news\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «It's not quite summer yet, though it might as well be ...»\n",
      "[2] «PRINCETON, NJ - The Princeton wrestling team announced Thursday that the program will be welcoming seven incoming freshman as a part of the Class of 2028.»\n",
      "[3] «The new true crime series — from the creators of the award-winning podcast \"Father Wants Us Dead\" — investigates the 1989 cold-case killing of a Princeton grande dame.»\n",
      "\n",
      "Question: Princeton\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m Reasoning: Let's think step by step in order to determine what specific information about Princeton is being sought. We have three pieces of context:\n",
      "\n",
      "1. A general statement about the season.\n",
      "2. An announcement from the Princeton wrestling team about incoming freshmen.\n",
      "3. A new true crime series related to a 1989 cold-case killing in Princeton.\n",
      "\n",
      "Since the question is simply \"Princeton,\" it is likely asking for a summary or key information related to Princeton from the provided contexts.\n",
      "\n",
      "Answer: The Princeton wrestling team announced that they will be welcoming seven incoming freshmen as part of the Class of 2028. Additionally, a new true crime series investigates the 1989 cold-case killing of a Princeton grande dame.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with the news in the context\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant news\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: highlights key points in context - often between 50-100 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «It's not quite summer yet, though it might as well be ...»\n",
      "[2] «PRINCETON, NJ - The Princeton wrestling team announced Thursday that the program will be welcoming seven incoming freshman as a part of the Class of 2028.»\n",
      "[3] «The new true crime series — from the creators of the award-winning podcast \"Father Wants Us Dead\" — investigates the 1989 cold-case killing of a Princeton grande dame.»\n",
      "\n",
      "Question: Princeton\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m Reasoning: Let's think step by step in order to identify the relevant information about Princeton from the context. We have three pieces of information: the weather, a wrestling team announcement, and a true crime series related to Princeton.\n",
      "\n",
      "Answer: The Princeton wrestling team announced that they will be welcoming seven incoming freshmen as part of the Class of 2028. Additionally, a new true crime series investigates the 1989 cold-case killing of a Princeton grande dame.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: ReAct Agent with Tools\n",
    "\n",
    "* Tools in ReAct can shape the agent's interaction and response mechanisms, and DSPy ensures this customizability by allowing users to pass in their toolsets tailored for their task scenarios. \n",
    "* The default tool is the `dspy.Retrieve` module (serving to retrieve information from Retrieval Models during the Action step) with default num_results=3, and these can be passed as arguments to the initialization of the ReAct module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class NewsModule(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a news module\n",
    "\n",
    "# create a search module\n",
    "\n",
    "# then, you can just make it a function (one line) and call it inside your DSPy program when needed!\n",
    "# If you want to use this with dspy.ReAct, then usage would be like:\n",
    "\n",
    "mytool = NewsModule()\n",
    "gen = dspy.ReAct('question -> answer', tools=[mytool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateResponse(dspy.Signature):\n",
    "    \"\"\"Answer questions with the news in the context\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant news\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 50-100 words\")\n",
    "\n",
    "# Pass signature to ReAct module\n",
    "react_module = dspy.ReAct(GenerateResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the ReAct module on a particular input\n",
    "question = 'What ?'\n",
    "result = react_module(question=question)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Final Predicted Answer (after ReAct process): {result.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
